{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "본 가이드에서는 Ansible을 통해 Confluent Platform을 설치 및 구성하는 방법을 다룹니다. \n",
    "\n",
    "- **Confluent Platform Version: 7.3.2**\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "# 1. Prerequisites\n",
    "\n",
    "![Confluent Ansible 7.3 을 사용하는 경우의 Prerequisites ](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/33b76007-ab63-4f7d-a2bf-11d4ede82712/Untitled.png)\n",
    "\n",
    "Confluent Ansible 7.3 을 사용하는 경우의 Prerequisites \n",
    "\n",
    "- **Ansible 2.11 + (Control Node)**\n",
    "- **Python 3.6 +  (Control Node/Managed Nodes)**\n",
    ": Confluent 7.2부터는 Python 2.x 지원하지 않으며, 본 가이드에서는 3.7.4 버전으로 진행.\n",
    "- **Ansible Control Node와 Confluent Platform Nodes 간의 양방향 SSH 통신 가능**\n",
    "    - **Public SSH Key 등록하기**\n",
    "        - Control Node에서 key 생성:  `$ ssh-keygen -t rsa`\n",
    "        - Control Node에서 Confluent Platform Node 로 Public key 전송:  \n",
    "        `$ ssh-copy-id -i ~/.ssh/id_rsa.pub confluent@<zookeeper-node-host>, \n",
    "         $ ssh-copy-id -i ~/.ssh/id_rsa.pub confluent@<broker-node-host>`\n",
    "            \n",
    "            ```bash\n",
    "            *# --- 확인* \n",
    "            \n",
    "            ***@ Confluent Platform Node: ~/.ssh/authorized_keys***\n",
    "            *ssh-rsa AAAAB3NzaC1yc2EAAAADAQAB~~~ confluent@control02\n",
    "            \n",
    "            **@ Ansible Control Node: ~/.ssh/known_hosts**\n",
    "            zk01, 192.168.137.100 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXN~~*\n",
    "            ```\n",
    "            \n",
    "- **SSH USER의 sudo 권한**\n",
    "- **JDK 11 이상**\n",
    ": 본 매뉴얼에서는 JDK 17 설치하여 진행\n",
    "- **[Optional] Confluent Platform Software (**packages.confluent.io)**에 대한 인터넷 연결**\n",
    ": 폐쇄망인 경우**,** [https://docs.confluent.io/ansible/current/ansible-airgap.html#air-gapped-deployment-of-ansible](https://docs.confluent.io/ansible/current/ansible-airgap.html#air-gapped-deployment-of-ansible) 참조\n",
    "- **Time Synchronization**\n",
    "\n",
    "**[ 설치/구성 파일 디렉터리 구조 ]**\n",
    "\n",
    "```bash\n",
    "**ansible**   *# 인터넷 연결 환경* ****\n",
    "├── ansible.cfg\n",
    "├── collections\n",
    "│   └── ansible_collections\n",
    "│       └── confluent\n",
    "│           └── platform\n",
    "│               ├── hosts.yml\n",
    "│               ├── docs\n",
    "│               ├── galaxy_importer\n",
    "│               ├── meta\n",
    "│               ├── molecule\n",
    "│               ├── playbooks\n",
    "│               ├── plugins\n",
    "│               ├── roles\n",
    "│               ├── test_roles\n",
    "│               └── tests\n",
    "├── source \n",
    "└── venv\n",
    "**private-ansible** *# 폐쇄망 환경* ****\n",
    "├── ansible.cfg\n",
    "├── collections\n",
    "│   └── confluent\n",
    "│       └── platform\n",
    "│           ├── hosts.yml\n",
    "│           ├── docs\n",
    "│           ├── galaxy_importer\n",
    "│           ├── meta\n",
    "│           ├── molecule\n",
    "│           ├── playbooks\n",
    "│           ├── plugins\n",
    "│           ├── roles\n",
    "│           ├── test_roles\n",
    "│           └── tests\n",
    "├── packages \n",
    "├── requirements.txt\n",
    "├── source \n",
    "└── venv\n",
    "```\n",
    "\n",
    "# 2. 환경 준비\n",
    "\n",
    "## 2-1. Python\n",
    "\n",
    "- ***python3 (Ansible Control Node 및  Managed Nodes)***\n",
    "\n",
    "```\n",
    "--- root 계정 \n",
    "\n",
    "# **cd /usr/src\n",
    "# wget https://www.python.org/ftp/python/3.7.4/Python-3.7.4.tgz\n",
    "# tar xzf Python-3.7.4.tgz**\n",
    "\n",
    "# **cd Python-3.7.4\n",
    "# ./configure --enable-optimizations**\n",
    "--- If error, **sudo yum -y groups install \"Development Tools\"**\n",
    "\n",
    "--- 기존의 /usr/bin/python 보호하며 추가설치 진행\n",
    "# **yum -y install libffi-devel zlib-devel openssl openssl-devel\n",
    "# make altinstall** \n",
    "*...\n",
    "Collecting setuptools\n",
    "Collecting pip\n",
    "Installing collected packages: setuptools, pip\n",
    "Successfully installed pip-19.0.3 setuptools-40.8.0\n",
    "\n",
    "#* **./python -V**\n",
    "*Python 3.7.4\n",
    "\n",
    "#* **ln -s /usr/src/Python-3.7.4/python /usr/bin/python3**\n",
    "\n",
    "*#* **python3**\n",
    "*Python 3.7.4 (default, Oct 28 2022, 09:41:39) \n",
    "...*\n",
    "```\n",
    "\n",
    "```\n",
    "**# python 의 디폴트 버전을 3.7 로 변경하는 경우 yum 명령어 사용이 불가해지는 경우**\n",
    "\n",
    "[root@zk01 ~]# python --version\n",
    "Python 3.7.4\n",
    "\n",
    "[root@zk01 ~]# yum -y install nginx\n",
    "  File \"/bin/yum\", line 30\n",
    "    except KeyboardInterrupt, e:\n",
    "                            ^\n",
    "SyntaxError: invalid syntax\n",
    "\n",
    "**### 해결 : 아래 두 파일에서 이용하는 python 의 버전을 2버전으로 명시해준다. \n",
    "\n",
    "$** vi /usr/bin/yum \n",
    "**$** vi /usr/libexec/urlgrabber-ext-down\n",
    "\n",
    "*#!/usr/bin/python\n",
    "=>\n",
    "#!/usr/bin/python2*\n",
    "```\n",
    "\n",
    "- ***pip3 (Ansible Control Node): 파이썬으로 작성된 패키지 라이브러리들을 관리해주는 시스템***\n",
    "\n",
    "```\n",
    "**# cd ~ \n",
    "# curl https://bootstrap.pypa.io/pip/get-pip.py -o get-pip.py\n",
    "# python get-pip.py**\n",
    "\n",
    "*Installing collected packages: wheel, pip\n",
    "  Attempting uninstall: pip\n",
    "    Found existing installation: pip 19.0.3\n",
    "    Uninstalling pip-19.0.3:\n",
    "      Successfully uninstalled pip-19.0.3\n",
    "Successfully installed pip-22.3 wheel-0.37.1*\n",
    "```\n",
    "\n",
    "- ***virtualenv (Ansible Control Node)***\n",
    "\n",
    "```bash\n",
    "# --- regular user로 변경하여 진행: 본 가이드에서는 confluent 계정으로 진행 \n",
    "\n",
    "**$ cd ~**\n",
    "**$ pip3 install virtualenv**\n",
    "*Successfully installed distlib-0.3.6 filelock-3.8.0 importlib-metadata-5.0.0 platformdirs-2.5.2 typing-extensions-4.4.0 virtualenv-20.16.6 zipp-3.10.0*\n",
    "```\n",
    "\n",
    "- ***venv (Ansible Control Node)*** **: 프로젝트 별로 파이썬 패키지 관리용**\n",
    "\n",
    "```bash\n",
    "# --- ansible용 디렉토리 생성 \n",
    "\n",
    "**$ mkdir ~/ansible ; cd ~/ansible** \n",
    "\n",
    "**$ virtualenv --python /usr/bin/python3 venv**\n",
    "*created virtual environment CPython3.6.8.final.0-64 in 803ms\n",
    "  creator CPython3Posix(dest=/home/confluent/ansible/venv, clear=False, no_vcs_ignore=False, global=False)\n",
    "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/home/confluent/.local/share/virtualenv)\n",
    "    added seed packages: pip==21.3.1, setuptools==59.6.0, wheel==0.37.1\n",
    "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator*\n",
    "\n",
    "**$ ll**\n",
    "*total 0\n",
    "drwxrwxr-x. 4 confluent confluent 64 Oct 28 10:06 venv*\n",
    "```\n",
    "\n",
    "## 2-2. Ansible 설치\n",
    "\n",
    "- **venv를 통한 가상 환경 활성화**\n",
    "\n",
    "```bash\n",
    "**$ cd ~/ansible**\n",
    "\n",
    "**$ source venv/bin/activate**\n",
    "\n",
    "**(venv) [confluent@control ansible]$ pip3 install ansible-core==2.11.0**\n",
    "\n",
    "*Successfully installed MarkupSafe-2.1.1 PyYAML-6.0 ansible-core-2.11.0 cffi-1.15.1 cryptography-38.0.1 jinja2-3.1.2 packaging-21.3 pycparser-2.21 pyparsing-3.0.9 resolvelib-0.5.4\n",
    "\n",
    "# ---- ansible.cfg 파일 생성:*\n",
    "\n",
    "**(venv) [confluent@control ansible]$ *vi ansible.cfg***\n",
    "*[defaults]\n",
    "hash_behaviour = merge\n",
    "collections_paths = /home/confluent/ansible/collections  # <--- ansible-collection 파일들이 설치 될 위치 지정\n",
    "host_key_checking = False \n",
    "deprecation_warnings = False\n",
    "stdout_callback = debug # <--- 앤서블 에러 출력화면 설정*\n",
    "```\n",
    "\n",
    "<aside>\n",
    "⚠️ **venv 가상 환경 비활성화하는 방법** :  *$ deactivate*\n",
    "\n",
    "(venv) [confluent@control ansible]$ **deactivate**\n",
    "[confluent@control ansible]$\n",
    "\n",
    "</aside>\n",
    "\n",
    "## 2-3. Ansible Playbook 설치\n",
    "\n",
    "```bash\n",
    "**(venv) [confluent@control ansible]$ ansible-galaxy collection install confluent.platform:7.3.2**\n",
    "\n",
    "****(venv) [confluent@control ansible]$ cd /home/confluent/ansible/ansible-galaxy/ansible_collections/confluent/platform**\n",
    "\n",
    "****(venv) [confluent@control platform]$ ll**\n",
    "*total 160\n",
    "-rw-r--r--.  1 confluent confluent    189 Oct 28 10:16 ansible.cfg\n",
    "drwxr-xr-x.  3 confluent confluent   4096 Oct 28 10:16 docs\n",
    "-rw-r--r--.  1 confluent confluent 121562 Oct 28 10:16 FILES.json\n",
    "drwxr-xr-x.  2 confluent confluent     33 Oct 28 10:16 galaxy_importer\n",
    "-rw-r--r--.  1 confluent confluent   5189 Oct 28 10:16 Jenkinsfile\n",
    "-rw-r--r--.  1 confluent confluent  11357 Oct 28 10:16 LICENSE.md\n",
    "-rw-r--r--.  1 confluent confluent    874 Oct 28 10:16 MANIFEST.json\n",
    "drwxr-xr-x.  2 confluent confluent     25 Oct 28 10:16 meta\n",
    "drwxr-xr-x. 57 confluent confluent   4096 Oct 28 10:16 molecule\n",
    "drwxr-xr-x.  3 confluent confluent    277 Oct 28 10:16 playbooks\n",
    "drwxr-xr-x.  4 confluent confluent     35 Oct 28 10:16 plugins\n",
    "-rw-r--r--.  1 confluent confluent   1083 Oct 28 10:16 README.md\n",
    "drwxr-xr-x. 14 confluent confluent    229 Oct 28 10:16 roles\n",
    "drwxr-xr-x.  5 confluent confluent     86 Oct 28 10:16 test_roles\n",
    "drwxr-xr-x.  3 confluent confluent     20 Oct 28 10:16 tests*\n",
    "```\n",
    "\n",
    "- test-hosts.yml작성한 다음, ping 테스트 진행\n",
    "\n",
    "```bash\n",
    "**(venv) [confluent@control ansible]$ cd /home/confluent/ansible/ansible-galaxy/ansible_collections/confluent/platform\n",
    "(venv) [confluent@control platform]$ vi test-ping.yml**\n",
    "\n",
    "*zookeeper:\n",
    "  hosts:\n",
    "    zk01:\n",
    "\n",
    "kafka_broker:\n",
    "  hosts:\n",
    "    br01: \n",
    "      broker_id: 1\n",
    "\n",
    "schema_registry:\n",
    "  hosts:\n",
    "    sr-ksql01:\n",
    "\n",
    "kafka_connect:\n",
    "  hosts:\n",
    "    cn01: \n",
    "\n",
    "control_center:\n",
    "  hosts:\n",
    "    control01:*\n",
    "\n",
    "**(venv) [confluent@red platform]$ ansible -i test-ping.yml all -m ping**\n",
    "```\n",
    "\n",
    "<aside>\n",
    "⚠️ **Python 의 default version이 3인 Ansible Managed Nodes 대상으로 yum 모듈이 들어간 task 실행하는 경우 아래 ERROR 발생:** \n",
    "\n",
    "`The Python 2 bindings for rpm are needed for this module. If you require Python 3 support use the `dnf` Ansible module instead.. The Python 2 yum module is needed for this module. If you require Python 3 support use the `dnf` Ansible module instead.\"`\n",
    "\n",
    "🔎 **Cause: yum module은 python 2에서만 정상 동작**\n",
    "\n",
    "****💡 **Solution (1) : 각 Ansible Managed Nodes 의 python default version을 2로 원복 후, ansible-playbook 실행 시 python 변수를 /usr/bin/python3 로 명시합니다.**\n",
    "\n",
    "```\n",
    "$ ansible-playbook -i hosts.yml confluent.platform.all --tags=zookeeper -e ansible_python_interpreter=/usr/bin/python3\n",
    "```\n",
    "\n",
    "💡 **Solution** **(2): 각 Ansible Managed Nodes 에 dnf 설치 후, Ansible Playbook 의 task에 선언된 yum 모듈을 모두 dnf 로 수정합니다.**\n",
    "\n",
    "```\n",
    "$ find -type f  -name \"main.yml\" | xargs sed -i \"s/yum:/dnf:/g\"\n",
    "$ find -type f  -name \"redhat.yml\" | xargs sed -i \"s/yum:/dnf:/g\"\n",
    "\n",
    "....\n",
    "- name: Install OpenSSL and Unzip\n",
    "  ~~yum: >>~~  dnf: \n",
    "    name:\n",
    "      - openssl\n",
    "      - unzip\n",
    "  tags: package\n",
    "....\n",
    "```\n",
    "\n",
    "</aside>\n",
    "\n",
    "# 3. General Configuration\n",
    "\n",
    "### 3-1. Confluent 설치 및 실행 방식 설정\n",
    "\n",
    "- ansible 실행 및 confluent 플랫폼별 실행할 OS 계정 설정\n",
    "\n",
    "```bash\n",
    "all:\n",
    "  vars:\n",
    "    ### ansible\n",
    "    ansible_connection: ssh\n",
    "    ansible_user: confluent\n",
    "    ansible_become: true # confluent 계정에서 sudo를 통해 root 사용자로 전환\n",
    "    mask_secrets: false\n",
    "    mask_sensitive_logs: false\n",
    "    mask_sensitive_diff: false\n",
    "\n",
    "    ### os user and group\n",
    "    archive_owner: confluent\n",
    "    archive_group: confluent\n",
    "    zookeeper_user: confluent\n",
    "    zookeeper_group: confluent\n",
    "    kafka_broker_user: confluent\n",
    "    kafka_broker_group: confluent\n",
    "    schema_registry_user: confluent\n",
    "    schema_registry_group: confluent\n",
    "    kafka_connect_user: confluent\n",
    "    kafka_connect_group: confluent\n",
    "    ksql_user: confluent\n",
    "    ksql_group: confluent\n",
    "    control_center_user: confluent\n",
    "    control_center_group: confluent\n",
    "```\n",
    "\n",
    "- java 설치 실행 여부 : 각 Ansible Managed Nodes에 설치되어있는 JDK17 경로를 명시합니다.\n",
    "\n",
    "```bash\n",
    "\t\t### jdk\n",
    "    custom_java_path: \"/usr/lib/jvm/jdk-17-oracle-x64\"\n",
    "```\n",
    "\n",
    "- confluent 설치 버전 및 방식 설정\n",
    "\n",
    "```bash\n",
    "\t\tconfluent_server_enabled: true\n",
    "    confluent_package_version: \"7.3.2\"   \n",
    "\n",
    "\t\tconfluent_cli_download_enabled: true\n",
    "    confluent_cli_version: \"2.30.1\"\n",
    "    confluent_cli_base_path: \"/engn/confluent_cli\"\n",
    "    confluent_cli_path: \"/usr/local/bin/confluent\"\n",
    "\n",
    "\t\t# installation_method: yum/apt방식(package)이 아닌 아카이브 파일을 다운로드 받아 설치 \n",
    "    installation_method: archive\n",
    "    archive_destination_path: \"/engn\"\n",
    "    confluent_archive_file_remote: true\n",
    "\n",
    "    # deployment_strategy: 한 번에 한 호스트에서만 task가 실행되는 방식(rolling), 동시 배포 방식(parallel) 중 설정 \n",
    "    deployment_strategy: rolling\n",
    "```\n",
    "\n",
    "### 3-2. Listener 설정\n",
    "\n",
    "- Kafka Listeners 설정\n",
    "\n",
    "```\n",
    "\t\t### kafka listeners\n",
    "    kafka_broker_configure_multiple_listeners: true\n",
    "    kafka_broker_configure_control_plane_listener: false\n",
    "    kafka_broker_inter_broker_listener_name: broker\n",
    "    kafka_broker_custom_listeners:\n",
    "      internal:\n",
    "        name: INTERNAL\n",
    "        port: 9092\n",
    "        sasl_protocol: none\n",
    "      broker:\n",
    "        name: BROKER\n",
    "        port: 9093\n",
    "        sasl_protocol: none\n",
    "\n",
    "    ### kafka internal listener\n",
    "    schema_registry_kafka_listener_name: internal\n",
    "    kafka_connect_kafka_listener_name: internal\n",
    "    kafka_rest_kafka_listener_name: internal\n",
    "    ksql_kafka_listener_name: internal\n",
    "    ksql_processing_log_kafka_listener_name: internal\n",
    "    control_center_kafka_listener_name: internal\n",
    "```\n",
    "\n",
    "### 3-3. 모니터링 및 로그 관련 파일 관련 설정\n",
    "\n",
    "- jmxexporter 관련 설정\n",
    "\n",
    "```bash\n",
    "\t\tjmxexporter_version: 0.17.2 \n",
    "    jmxexporter_enabled: true\n",
    "    jmxexporter_url_remote: true # 인터넷에서 다운받도록 설정 \n",
    "    jmxexporter_jar_path: \"{{archive_destination_path}}/prometheus/jmx_prometheus_javaagent.jar\"\n",
    "    zookeeper_jmxexporter_config_path: \"{{archive_destination_path}}/prometheus/zookeeper.yml\"\n",
    "    zookeeper_jmxexporter_port: 1234\n",
    "\t\t...\n",
    "```\n",
    "\n",
    "- log4j 파일 관련 설정\n",
    ": source_path 로 지정한 경로 아래에 배포할 파일들을 위치시킵니다.\n",
    "\n",
    "```bash\n",
    "\t\tzookeeper_copy_files:\n",
    "      - source_path: \"/home/confluent/ansible/source/log4j/zookeeper-log4j.properties\"\n",
    "        destination_path: \"{{archive_destination_path}}/log4j/zookeeper-log4j.properties\"\n",
    "    kafka_broker_copy_files:\n",
    "      - source_path: \"/home/confluent/ansible/source/log4j/kafka-log4j.properties\"\n",
    "        destination_path: \"{{archive_destination_path}}/log4j/kafka-log4j.properties\"\n",
    "\t\t...\n",
    "```\n",
    "\n",
    "<aside>\n",
    "<img src=\"/icons/arrow-down_lightgray.svg\" alt=\"/icons/arrow-down_lightgray.svg\" width=\"40px\" /> **[DOWNLOAD] log4j.properties**\n",
    "\n",
    "[zookeeper-log4j.properties](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/733fef1a-7bd4-41f4-96c5-bd12a9b51b9b/zookeeper-log4j.properties)\n",
    "\n",
    "[kafka-log4j.properties](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/694b53a6-5bab-43e8-9627-bdb0eb23f0be/kafka-log4j.properties)\n",
    "\n",
    "[kafka-connect-log4j.properties](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/90518b8d-650d-4b09-8a9e-2285049825e3/kafka-connect-log4j.properties)\n",
    "\n",
    "[schema-registry-log4j.properties](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/5eeb9492-2266-4c22-86a3-7b46410349ad/schema-registry-log4j.properties)\n",
    "\n",
    "[ksqldb-log4j.properties](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/f58e1c2b-5e54-4e3c-a9e2-6a63f9e1e782/ksqldb-log4j.properties)\n",
    "\n",
    "[control-center-log4j.properties](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/2ed7a2e5-9be4-4435-875d-e915c13dd057/control-center-log4j.properties)\n",
    "\n",
    "</aside>\n",
    "\n",
    "### 3-4. Component 별 설정\n",
    "\n",
    "- zookeeper 설정 정보\n",
    "\n",
    "```\n",
    "\t\tzookeeper_log_dir: /logs/zookeeper\n",
    "    zookeeper_chroot: /confluent\n",
    "\n",
    "    zookeeper_service_environment_overrides:\n",
    "      KAFKA_HEAP_OPTS: \"-Xms512m -Xmx512m\"\n",
    "      KAFKA_JVM_PERFORMANCE_OPTS: \"-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.awt.headless=true\"\n",
    "      KAFKA_GC_LOG_OPTS: \"-Xlog:gc*:file={{zookeeper_log_dir}}/zookeeper-gc.log:time,tags:filecount=10,filesize=100M\"\n",
    "      KAFKA_JMX_OPTS: \"-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false\"\n",
    "      KAFKA_LOG4J_OPTS: \"-Dlog4j.configuration=file:{{archive_destination_path}}/log4j/zookeeper-log4j.properties\"\n",
    "\n",
    "\t\tzookeeper_custom_properties:\n",
    "      dataDir: /data/zookeeper\n",
    "      tickTime: 2000\n",
    "      initLimit: 5\n",
    "      syncLimit: 2\n",
    "      maxClientCnxns: 0\n",
    "      autopurge.snapRetainCount: 10\n",
    "      autopurge.purgeInterval: 1\n",
    "      admin.enableServer: \"false\"\n",
    "      4lw.commands.whitelist: ruok,stat,srvr\n",
    "```\n",
    "\n",
    "- broker 설정 정보\n",
    "\n",
    "```\n",
    "\t\tkafka_broker_log_dir: /logs/kafka\n",
    "\n",
    "    kafka_broker_service_environment_overrides:\n",
    "      KAFKA_HEAP_OPTS: \"-Xms4g -Xmx4g\"\n",
    "      KAFKA_JVM_PERFORMANCE_OPTS: \"-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.awt.headless=true\"\n",
    "      KAFKA_GC_LOG_OPTS: \"-Xlog:gc*:file={{kafka_broker_log_dir}}/kafka-gc.log:time,tags:filecount=10,filesize=100M\"\n",
    "      KAFKA_JMX_OPTS: \"-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false\"\n",
    "      KAFKA_LOG4J_OPTS: \"-Dlog4j.configuration=file:{{archive_destination_path}}/log4j/kafka-log4j.properties\"\n",
    "\n",
    "\t\tkafka_broker_custom_properties:\n",
    "      log.dirs: /data/kafka\n",
    "      log.retention.hours: 168\n",
    "      log.retention.check.interval.ms: 300000\n",
    "      log.segment.bytes: 1073741824\n",
    "      log.cleanup.policy: delete\n",
    "      num.partitions: 3\n",
    "      num.recovery.threads.per.data.dir: 2\n",
    "      default.replication.factor: 3\n",
    "      min.insync.replicas: 2\n",
    "      replica.lag.time.max.ms: 30000\n",
    "      unclean.leader.election.enable: \"false\"\n",
    "      auto.create.topics.enable: \"false\"\n",
    "      group.initial.rebalance.delay.ms: 3000\n",
    "      offsets.topic.replication.factor: 3\n",
    "      transaction.state.log.min.isr: 2\n",
    "      transaction.state.log.replication.factor: 3\n",
    "      confluent.balancer.enable: \"true\"\n",
    "      confluent.balancer.heal.uneven.load.trigger: EMPTY_BROKER\n",
    "      confluent.balancer.disk.max.load: 0.85\n",
    "      confluent.balancer.topic.replication.factor: 3\n",
    "      confluent.tier.enable: \"false\"\n",
    "```\n",
    "\n",
    "- schema-registry 설정 정보\n",
    "\n",
    "```\n",
    "\t\tschema_registry_log_dir: /logs/schema-registry\n",
    "    schema_registry_service_environment_overrides:\n",
    "      SCHEMA_REGISTRY_HEAP_OPTS: \"-Xms512m -Xmx512m\"\n",
    "      SCHEMA_REGISTRY_JVM_PERFORMANCE_OPTS: \"-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.awt.headless=true\"\n",
    "      SCHEMA_REGISTRY_GC_LOG_OPTS: \"-Xlog:gc*:file={{schema_registry_log_dir}}/schema-registry-gc.log:time,tags:filecount=10,filesize=100M\"\n",
    "      SCHEMA_REGISTRY_JMX_OPTS: \"-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false\"\n",
    "      SCHEMA_REGISTRY_LOG4J_OPTS: \"-Dlog4j.configuration=file:{{archive_destination_path}}/log4j/schema-registry-log4j.properties\"\n",
    "\n",
    "    schema_registry_custom_properties:\n",
    "      schema.compatibility.level: full\n",
    "```\n",
    "\n",
    "- connect worker 설정 정보\n",
    "\n",
    "```\n",
    "\t\tkafka_connect_log_dir: /logs/kafka-connect\n",
    "    kafka_connect_service_environment_overrides:\n",
    "      KAFKA_HEAP_OPTS: \"-Xms4g -Xmx4g\"\n",
    "      KAFKA_JVM_PERFORMANCE_OPTS: \"-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.awt.headless=true\"\n",
    "      KAFKA_GC_LOG_OPTS: \"-Xlog:gc*:file={{kafka_connect_log_dir}}/connect-gc.log:time,tags:filecount=10,filesize=100M\"\n",
    "      KAFKA_JMX_OPTS: \"-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false\"\n",
    "      KAFKA_LOG4J_OPTS: \"-Dlog4j.configuration=file:{{archive_destination_path}}/log4j/kafka-connect-log4j.properties\"\n",
    "      CLASSPATH: \"{{archive_destination_path}}/confluent-{{confluent_package_version}}/share/java/kafka-connect-replicator/*\"\n",
    "\n",
    "    kafka_connect_custom_properties:\n",
    "      config.storage.replication.factor: 3\n",
    "      offset.storage.partitions: 25\n",
    "      offset.storage.replication.factor: 3\n",
    "      offset.flush.interval.ms: 10000\n",
    "      status.storage.partitions: 5\n",
    "      status.storage.replication.factor: 3\n",
    "      connector.client.config.override.policy: All\n",
    "\n",
    "    kafka_connect_custom_rest_extension_classes:\n",
    "      - io.confluent.connect.replicator.monitoring.ReplicatorMonitoringExtension\n",
    "\n",
    "\t\tkafka_connect_plugins_path:\n",
    "      - \"{{archive_destination_path}}/connect/plugins\"\n",
    "\n",
    "    kafka_connect_plugins_dest: \"{{archive_destination_path}}/connect/plugins\"\n",
    "```\n",
    "\n",
    "- ksql 설정 정보\n",
    "\n",
    "```\n",
    "\t\tksql_log_dir: /logs/ksqldb\n",
    "    ksql_service_environment_overrides:\n",
    "      KSQL_HEAP_OPTS: \"-Xms1g -Xmx1g\"\n",
    "      KSQL_JVM_PERFORMANCE_OPTS: \"-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.awt.headless=true\"\n",
    "      KSQL_GC_LOG_OPTS: \"-Xlog:gc*:file={{ksql_log_dir}}/ksql-server-gc.log:time,tags:filecount=10,filesize=100M\"\n",
    "      KSQL_JMX_OPTS: \"-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false\"\n",
    "      KSQL_LOG4J_OPTS: \"-Dlog4j.configuration=file:{{archive_destination_path}}/log4j/ksqldb-log4j.properties\"\n",
    "\n",
    "    ksql_custom_properties:\n",
    "      ksql.streams.state.dir: /data/ksqldb\n",
    "```\n",
    "\n",
    "- control center 설정 정보\n",
    "\n",
    "```\n",
    "\t\tcontrol_center_log_dir: /logs/control-center\n",
    "    control_center_custom_java_args: \"-Xlog:gc*:file={{control_center_log_dir}}/control-center-gc.log:time,tags:filecount=10,filesize=\n",
    "100M\"\n",
    "    control_center_service_environment_overrides:\n",
    "      CONTROL_CENTER_HEAP_OPTS: \"-Xms4g -Xmx4g\"\n",
    "      CONTROL_CENTER_JVM_PERFORMANCE_OPTS: \"-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.awt.headless=true\"\n",
    "      CONTROL_CENTER_JMX_OPTS: \"-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false\"\n",
    "      CONTROL_CENTER_LOG4J_OPTS: \"-Dlog4j.configuration=file:{{archive_destination_path}}/log4j/control-center-log4j.properties\"\n",
    "\n",
    "    control_center_service_overrides:\n",
    "      Restart: \"no\"\n",
    "\n",
    "\t\tcontrol_center_custom_properties:\n",
    "      confluent.controlcenter.data.dir: /data/control-center\n",
    "      confluent.controlcenter.command.topic: _confluent-command\n",
    "      confluent.controlcenter.command.topic.replication: 3\n",
    "      confluent.controlcenter.internal.topics.partitions: 12\n",
    "      confluent.controlcenter.internal.topics.replication: 3\n",
    "      confluent.metrics.topic: _confluent-metrics\n",
    "      confluent.metrics.topic.partitions: 12\n",
    "      confluent.metrics.topic.replication: 3\n",
    "      confluent.controlcenter.streams.num.stream.threads: 8\n",
    "      confluent.controlcenter.ui.autoupdate.enable: \"false\"\n",
    "      confluent.controlcenter.ui.controller.chart.enable: \"true\"\n",
    "      confluent.controlcenter.usage.data.collection.enable: \"false\"\n",
    "\t\t\tconfluent.controlcenter.id: test01\n",
    "      confluent.controlcenter.name: test01\n",
    "```\n",
    "\n",
    "- Confluent Platform Node 정보\n",
    "\n",
    "```bash\n",
    "zookeeper:\n",
    "  # vars:\n",
    "  hosts:\n",
    "    zk01:\n",
    "      zookeeper_id: 1\n",
    "    br01:\n",
    "      zookeeper_id: 2\n",
    "    sr-ksql01:\n",
    "      zookeeper_id: 3\n",
    "\n",
    "kafka_broker:\n",
    "  # vars:\n",
    "  hosts:\n",
    "    zk01:\n",
    "      broker_id: 1\n",
    "    br01:\n",
    "      broker_id: 2\n",
    "    sr-ksql01:\n",
    "      broker_id: 3\n",
    "\n",
    "schema_registry:\n",
    "  vars:\n",
    "    schema_registry_custom_properties:\n",
    "      schema.registry.group.id: schema-cluster1\n",
    "  hosts:\n",
    "    sr-ksql01:\n",
    "\n",
    "kafka_connect:\n",
    "  children:\n",
    "    connect-cluster1:\n",
    "      vars:\n",
    "        kafka_connect_group_id: connect-cluster1\n",
    "      hosts:\n",
    "        cn01:\n",
    "\n",
    "ksql:\n",
    "  children:\n",
    "    ksql-cluster1:\n",
    "      vars:\n",
    "        ksql_service_id: ksql-cluster1\n",
    "      hosts:\n",
    "        control01:\n",
    "\n",
    "control_center:\n",
    "  # vars:\n",
    "  hosts:\n",
    "    control01:\n",
    "```\n",
    "\n",
    "<aside>\n",
    "<img src=\"/icons/forward_lightgray.svg\" alt=\"/icons/forward_lightgray.svg\" width=\"40px\" /> **[DOWNLOAD] hosts.yml**\n",
    "\n",
    "[hosts.yml](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/7fb8f109-a95f-4229-ae8a-ed304e0e9711/hosts.yml)\n",
    "\n",
    "</aside>\n",
    "\n",
    "# 4. Install Confluent Platform\n",
    "\n",
    "### 4-1. 전체 플랫폼 설치 및 기동\n",
    "\n",
    "```bash\n",
    "$ ansible-playbook -i hosts.yml confluent.platform.all\n",
    "```\n",
    "\n",
    "### 4-2. 컴포넌트별 설치 및 기동\n",
    "\n",
    "```bash\n",
    "$ ansible-playbook -i hosts.yml confluent.platform.all --tags=zookeeper\n",
    "$ ansible-playbook -i hosts.yml confluent.platform.all --tags=kafka_broker\n",
    "$ ansible-playbook -i hosts.yml confluent.platform.all --tags=schema_registry\n",
    "$ ansible-playbook -i hosts.yml confluent.platform.all --tags=ksql\n",
    "$ ansible-playbook -i hosts.yml confluent.platform.all --tags=kafka_connect\n",
    "$ ansible-playbook -i hosts.yml confluent.platform.all --tags=control_center\n",
    "```\n",
    "\n",
    "# 5. Airgapped Deployment : 폐쇄망 환경 내 ansible 설치\n",
    "\n",
    "폐쇄망 환경에서는 Ansible 설치 및 배포에 필요한 필요한 패키지를 미리 다운로드 받아 준비해야 합니다. \n",
    "\n",
    "이 과정에서 별도의 distribution server 가 필요한데, 해당 서버는 ansible-galaxy가 설치되어 있으며, 인터넷 연결이 가능해야 합니다. \n",
    "\n",
    "<aside>\n",
    "💡 Airgapped Deployment 설치 가이드는 폐쇄망 ansible 실습용으로 별도의 디렉토리를 생성하여 파이썬 가상환경(venv) 을 새로 생성하고 시작합니다.\n",
    "\n",
    "***@ Ansible Control Node***\n",
    " *$ mkdir ~/private-ansible ; cd ~/private-ansible\n",
    " $ virtualenv --python /usr/bin/python3 venv\n",
    " $ source venv/bin/activate*\n",
    "\n",
    "</aside>\n",
    "\n",
    "## 5-1. Ansible 설치\n",
    "\n",
    "distribution server를 통해 Ansible을 설치하기 위해 필요한 패키지를 미리 다운로드 받고,\n",
    "Ansible-control node에 해당 파일들을 업로드하여 ansible을 설치합니다. \n",
    "\n",
    "- ***distribution server***\n",
    "\n",
    "```bash\n",
    "*# --- 패키지를 다운받을 디렉토리 준비*\n",
    "**$ mkdir ~/packages\n",
    "\n",
    "$ vi ~/requirements.txt**\n",
    "*virtualenv>=20.16.5\n",
    "ansible>=2.11*\n",
    "\n",
    "**$ pip3 download --requirement requirements.txt --dest packages**\n",
    "...\n",
    "*Successfully downloaded virtualenv ansible ansible-core distlib filelock importlib-metadata platformdirs resolvelib typing-extensions zipp cryptography jinja2 packaging PyYAML cffi MarkupSafe pyparsing pycparser*\n",
    "\n",
    "**$ ll ~/packages**\n",
    "total 57556\n",
    "-rw-rw-r-- 1 confluent confluent 36832606 Sep 19 13:10 ansible-4.10.0.tar.gz\n",
    "-rw-rw-r-- 1 confluent confluent  7118115 Sep 19 13:10 ansible-core-2.11.12.tar.gz\n",
    "-rw-rw-r-- 1 confluent confluent   427911 Sep 19 13:10 cffi-1.15.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "-rw-rw-r-- 1 confluent confluent  4143904 Sep 19 13:10 cryptography-38.0.1-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "-rw-rw-r-- 1 confluent confluent   468535 Sep 19 13:10 distlib-0.3.6-py2.py3-none-any.whl\n",
    "-rw-rw-r-- 1 confluent confluent    10057 Sep 19 13:10 filelock-3.8.0-py3-none-any.whl\n",
    "-rw-rw-r-- 1 confluent confluent    21704 Sep 19 13:10 importlib_metadata-4.12.0-py3-none-any.whl\n",
    "-rw-rw-r-- 1 confluent confluent   133101 Sep 19 13:10 Jinja2-3.1.2-py3-none-any.whl\n",
    "-rw-rw-r-- 1 confluent confluent    25334 Sep 19 13:10 MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "-rw-rw-r-- 1 confluent confluent    40750 Sep 19 13:10 packaging-21.3-py3-none-any.whl\n",
    "-rw-rw-r-- 1 confluent confluent    14416 Sep 19 13:10 platformdirs-2.5.2-py3-none-any.whl\n",
    "-rw-rw-r-- 1 confluent confluent   118697 Sep 19 13:10 pycparser-2.21-py2.py3-none-any.whl\n",
    "-rw-rw-r-- 1 confluent confluent    98338 Sep 19 13:10 pyparsing-3.0.9-py3-none-any.whl\n",
    "-rw-rw-r-- 1 confluent confluent   596265 Sep 19 13:10 PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
    "-rw-rw-r-- 1 confluent confluent    12807 Sep 19 13:10 resolvelib-0.5.4-py2.py3-none-any.whl\n",
    "-rw-rw-r-- 1 confluent confluent    25596 Sep 19 13:10 typing_extensions-4.3.0-py3-none-any.whl\n",
    "-rw-rw-r-- 1 confluent confluent  8805743 Sep 19 13:10 virtualenv-20.16.5-py3-none-any.whl\n",
    "-rw-rw-r-- 1 confluent confluent     5645 Sep 19 13:10 zipp-3.8.1-py3-none-any.whl\n",
    "\n",
    "*# --- ansible control node에 업로드* \n",
    "**$ scp -r packages <control-node>:/home/confluent/private-ansible\n",
    "$ scp requirements.txt <control-node>:/home/confluent/private-ansible**\n",
    "```\n",
    "\n",
    "- ***Ansible Control Node***\n",
    "\n",
    "반입한 패키지들을 통해 Ansible 및 의존성 라이브러리들을 설치합니다. \n",
    "\n",
    "```bash\n",
    "**(venv) $ cd /home/confluent/private-ansible\n",
    "(venv) $ pip3 install --no-index --find-links=./packages/ --requirement requirements.txt\n",
    "*...***\n",
    "*Successfully built ansible ansible-core*\n",
    "*****Installing collected packages: resolvelib, distlib, zipp, typing-extensions, PyYAML, pyparsing, pycparser, platformdirs, MarkupSafe, filelock, packaging, jinja2, importlib-metadata, cffi, virtualenv, cryptography, ansible-core, ansible\n",
    "Successfully installed MarkupSafe-2.1.1 PyYAML-6.0 ansible-4.10.0 ansible-core-2.11.12 cffi-1.15.1 cryptography-38.0.1 distlib-0.3.6 filelock-3.8.0 importlib-metadata-4.12.0 jinja2-3.1.2 packaging-21.3 platformdirs-2.5.2 pycparser-2.21 pyparsing-3.0.9 resolvelib-0.5.4 typing-extensions-4.3.0 virtualenv-20.16.5 zipp-3.8.1*\n",
    "```\n",
    "\n",
    "## 5-2. Ansible Playbooks 다운로드 및 Collection Build 작업\n",
    "\n",
    "distribution server에서 Confluent Platform collection build 한 다음, 해당 collection 을 Ansible-control node에 업로드하여 설치합니다. \n",
    "\n",
    "- ***distribution server***\n",
    "\n",
    "```bash\n",
    "**$** **git clone https://github.com/confluentinc/cp-ansible.git\n",
    "$ cd cp-ansible\n",
    "$ git checkout 7.3.3-post\n",
    "$ ansible-galaxy collection build**\n",
    "\n",
    "**## ansible control node에 업로드\n",
    "****$ scp confluent-platform-7.3.3.tar.gz <control-node>:/home/confluent/private-ansible**\n",
    "```\n",
    "\n",
    "- ***Ansible Control Node***\n",
    "\n",
    "```bash\n",
    "**$ cd /home/confluent/private-ansible**\n",
    "\n",
    "*# ---- ansible.cfg 파일 생성*\n",
    "**$ vi /home/confluent/private-ansible/ansible.cfg** \n",
    "*[defaults]\n",
    "hash_behaviour = merge\n",
    "collections_paths = **/home/confluent/private-ansible**\n",
    "host_key_checking = False \n",
    "deprecation_warnings=False*\n",
    "\n",
    "**$ ansible-galaxy collection install confluent-platform-7.3.3.tar.gz**\n",
    "```\n",
    "\n",
    "## 5-3. Confluent Platform archive 및 기타 파일 준비\n",
    "\n",
    "- ***distribution server***\n",
    "\n",
    "```bash\n",
    "*# ---  confluent platform archive 파일 다운로드*\n",
    "**$ curl -O https://packages.confluent.io/archive/7.3/confluent-community-7.3.2.tar.gz**\n",
    "\n",
    "*# --- monitoring jar 파일 다운로드* \n",
    "**$ curl -O https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.17.2/jmx_prometheus_javaagent-0.17.2.jar**\n",
    "\n",
    "*# --- log4j.properties 파일 업로드*\n",
    "```\n",
    "\n",
    "- ***Ansible Control Node***\n",
    "\n",
    "```bash\n",
    "*# --- Confluent Componet Node에 배포할 파일들을 위치할 디렉토리 생성*\n",
    "**$ mkdir /home/confluent/private-ansible/source**\n",
    "```\n",
    "\n",
    "- ***distribution server***\n",
    "\n",
    "```bash\n",
    "*# --- ansible control node에 배포할 파일들 업로드*\n",
    "**$ scp confluent-7.3.2.tar.gz <control-node>:/home/confluent/private-ansible/source\n",
    "$ scp jmx_prometheus_javaagent-0.17.2.jar <control-node>:/home/confluent/private-ansible/source\n",
    "$ scp *-log4j.properties <control-node>:/home/confluent/private-ansible/source**\n",
    "```\n",
    "\n",
    "## 5-4. Configurations for private-ansible\n",
    "\n",
    "- ***Ansible Control Node : hosts.yml 수정***\n",
    "\n",
    "```bash\n",
    "#-- confluent_cli download 비활성화\n",
    "\t\t*confluent_cli_download_enabled: false*\n",
    "\n",
    "# -- archvie deployment 방식으로 배포할 수 있도록 설정)\n",
    "\t\tinstallation_method: archive\n",
    "    archive_destination_path: \"/engn/confluent\"\n",
    "    confluent_archive_file_remote: false\n",
    "    *confluent_archive_file_source: \"/home/confluent/private-ansible/source/confluent-7.3.2.tar.gz\"* \n",
    "...\n",
    "    jmxexporter_enabled: true\n",
    "    jmxexporter_url_remote: false\n",
    "    *jmxexporter_jar_url: \"/home/confluent/private-ansible/source/jmx_prometheus_javaagent-0.17.2.jar\"*\n",
    "...\n",
    "\t\tzookeeper_copy_files:\n",
    "      - *source_path: \"/home/confluent/private-ansible/source/log4j/zookeeper-log4j.properties\"*\n",
    "        destination_path: \"{{archive_destination_path}}/log4j/zookeeper-log4j.properties\"\n",
    "**\n",
    "*### ansible-playbook 실행* \n",
    "**$ ansible-playbook -i hosts.yml confluent.platform.all**\n",
    "```\n",
    "\n",
    "<aside>\n",
    "<img src=\"/icons/forward_lightgray.svg\" alt=\"/icons/forward_lightgray.svg\" width=\"40px\" /> **[DOWNLOAD] hosts-private.yml**\n",
    "\n",
    "[hosts-private.yml](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e4df5a9c-dc34-47f5-b809-14300c972176/hosts-private.yml)\n",
    "\n",
    "</aside>\n",
    "\n",
    "# 6. Reconfigure Confluent Platform\n",
    "\n",
    "Confluent Platform Component 설정 중 변경 사항이 있는 경우 hosts.yml 을 수정한 다음, \n",
    " `--skip-tags package` 을 통해 패키지 설치 task 부분은 건너뛰고 ansible-playbook을 실행한다. \n",
    "\n",
    "### 6-1. Update Confluent Platform configuration\n",
    "\n",
    "```bash\n",
    "**$ ansible-playbook -i hosts.yml confluent.platform.all --skip-tags package --extra-vars deployment_strategy=rolling**\n",
    "\n",
    "*...\n",
    "TASK [confluent.platform.zookeeper : Write Service Overrides] ******************************************************************************\n",
    "Monday 19 September 2022  14:55:50 +0900 (0:00:00.641)       0:00:37.477 ****** \n",
    "--- before: /etc/systemd/system/confluent-zookeeper.service.d/override.conf\n",
    "+++ after: /home/confluent/.ansible/tmp/ansible-local-56918jugam8jp/tmp_t12ln6s/override.conf.j2\n",
    "@@ -3,7 +3,7 @@\n",
    " # If there is an ExecStart override then we need to clear the ExecStart list first\n",
    " ExecStart=\n",
    " ExecStart=/engn/confluent/confluent-7.2.1/bin/zookeeper-server-start /engn/confluent/etc/kafka/zookeeper.properties\n",
    "-Environment=\"KAFKA_HEAP_OPTS=-Xms256m -Xmx512m\"\n",
    "+Environment=\"KAFKA_HEAP_OPTS=-Xms512m -Xmx512m\"\n",
    " Environment=\"KAFKA_OPTS=-javaagent:/engn/confluent/prometheus/jmx_prometheus_javaagent.jar=1234:/engn/confluent/prometheus/zookeeper.yml\"\n",
    " Environment=\"KAFKA_LOG4J_OPTS\n",
    "...*\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# Appendix A. Trouble Shooting\n",
    "\n",
    "<aside>\n",
    "⚠️ **ERROR: Ansible-playbook 실행 시 ImportError: cannot import name 'environmentfilter' from 'jinja2' 발생\n",
    ">>> 💡 Solution: jinja2를 3.0.1 로 downgrade**\n",
    " `$ pip3 install --upgrade jinja2==3.0.1`\n",
    "\n",
    "</aside>\n",
    "\n",
    "<aside>\n",
    "⚠️ **ERROR: Ansible-playbook 실행 시 “debug3: mux_client_read_packet: read header failed: Broken pipe” 발생\n",
    ">>> 💡 Solution: 에러가 발생한 특정 yml 파일에서 environmentfilter 부분 수정**\n",
    "\n",
    "```bash\n",
    "1. *from jinja2.filters import ~~environmentfilter~~* >> \n",
    "**try:    from jinja2.filters import environmentfilter as pass_environment\n",
    "except ImportError: # renamed in jinja2 3.1\n",
    "    from jinja2.filters import pass_environment**\n",
    "\n",
    "2. *~~@environmentfilter~~ >>*  **@pass_environment**  \n",
    "```\n",
    "\n",
    "</aside>\n",
    "\n",
    "# Appendix. B: Configure TLS Encryption\n",
    "\n",
    "### B-1. 각 서버별 Keystore 및  Truststore 파일 준비\n",
    "\n",
    ": 아래 절차에 따라 각 Confluent Platform Nodes 상에 Keystore를 구성하여 준비한다. \n",
    "\n",
    "```bash\n",
    "# ------- 모든 Platform Nodes가 동일하게 사용할 Root CA 와 Truststore 구성 \n",
    "\n",
    "### Crate the Root CA : private key & root CA 생성\n",
    "openssl genrsa -out root.key\n",
    "openssl req -new -x509 -key root.key -out root.crt\n",
    "\n",
    "### set permission for files\n",
    "chmod 600 root.key\n",
    "chmod 644 root.crt\n",
    "\n",
    "# ------- Configure Truststroe file for all the Nodes \n",
    "keytool -keystore kafka.truststore.p12 -alias CARoot -import  -file root.crt  -storetype pkcs12\n",
    "scp kafka.truststore root.key  root.crt  confluent@<ansible-control-node>:~/ssl\n",
    "\n",
    "# ------- 아래 절차는 각 node에 맞게 hostname 다르게 하여 수행 (ex: \"zk01\" node) \n",
    "### Configure Unique Keystore for Platform Nodes \n",
    "keytool -keystore zk01.keystore.p12 -alias localhost -validity 365 -genkey -keyalg RSA  -ext san=dns:zk01 -storetype pkcs12\n",
    "\n",
    "### Create signed crt \n",
    "keytool -keystore zk01.keystore.p12 -alias localhost  -certreq -file zk01.unsigned.crt\n",
    "openssl x509 -req -CA root.crt -CAkey root.key -in zk01.unsigned.crt  -out zk01.signed.crt -days 365 -CAcreateserial\n",
    "\"Signature ok\n",
    "subject=/C=KR/ST=SEOUL/L=SEOUL/O=TG/OU=DS/CN=SONYE\n",
    "Getting CA Private Key\"\n",
    "\n",
    "### import rootCa > Keystore \n",
    "keytool -keystore zk01.keystore.p12  -alias CARoot -import -file root.crt\n",
    "\"Certificate was added to keystore\"\n",
    "\n",
    "### import signedCrt > Keystore \n",
    "keytool -keystore zk01.keystore.p12   -alias localhost    -import -file zk01.signed.crt \n",
    "keytool -keystore br01.keystore.p12 -alias localhost    -import -file br01.signed.crt \n",
    "keytool -keystore sr-ksql01.keystore.p12  -alias localhost    -import -file sr-ksql01.signed.crt \n",
    "keytool -keystore cn01.keystore.p12  -alias localhost    -import -file cn01.signed.crt \n",
    "keytool -keystore control01.keystore.p12  -alias localhost    -import -file control01.signed.crt \n",
    "\"Certificate reply was installed in keystore\"\n",
    "```\n",
    "\n",
    "### B-2. hosts.yml 수정\n",
    "\n",
    "- SSL 관련 설정 추가:\n",
    "\n",
    "```bash\n",
    "---\n",
    "all:\n",
    "  vars:\n",
    "    ssl_enabled: true\n",
    "    ssl_mutual_auth_enabled: true\n",
    "    ssl_provided_keystore_and_truststore: true\n",
    "    ssl_provided_keystore_and_truststore_remote_src: true\n",
    "```\n",
    "\n",
    "- broker listener 추가:\n",
    "\n",
    "```bash\n",
    "    ### kafka listeners\n",
    "    kafka_broker_configure_multiple_listeners: true\n",
    "    kafka_broker_configure_control_plane_listener: false\n",
    "    kafka_broker_inter_broker_listener_name: broker\n",
    "    kafka_broker_custom_listeners:\n",
    "      internal:\n",
    "        name: INTERNAL\n",
    "        port: 9092\n",
    "        ssl_enabled: true\n",
    "        sasl_protocol: none\n",
    "      broker:\n",
    "        name: BROKER\n",
    "        port: 9093\n",
    "        ssl_enabled: true\n",
    "        sasl_protocol: none\n",
    "```\n",
    "\n",
    "- 각 component 별 keystore/truststore 관련 정보 명시:\n",
    "\n",
    "```bash\n",
    "zookeeper:\n",
    "  # vars:\n",
    "  hosts:\n",
    "    zk01:\n",
    "      zookeeper_id: 1\n",
    "      ssl_keystore_filepath: \"/home/confluent/ssl/zk01.keystore.p12\"\n",
    "      ssl_keystore_key_password: test1234\n",
    "      ssl_keystore_store_password: test1234\n",
    "      ssl_keystore_alias: localhost\n",
    "      ssl_truststore_filepath: \"/home/confluent/ssl/kafka.truststore.p12\"\n",
    "      ssl_truststore_password: test1234\n",
    "      ssl_truststore_ca_cert_alias: caroot\n",
    "```\n",
    "\n",
    "### B-3. 결과\n",
    "\n",
    "- Zookeeper/Broker 서버에 생성된 client.properties\n",
    "\n",
    "```bash\n",
    "[confluent@zk01 kafka]$ cat zookeeper-tls-client.properties\n",
    "# Maintained by Ansible\n",
    "zookeeper.clientCnxnSocket=org.apache.zookeeper.ClientCnxnSocketNetty\n",
    "zookeeper.ssl.client.enable=true\n",
    "zookeeper.ssl.truststore.location=/home/confluent/ssl/kafka.truststore.p12\n",
    "zookeeper.ssl.truststore.password=test1234\n",
    "zookeeper.ssl.keystore.location=/home/confluent/ssl/zk01.keystore.p12\n",
    "zookeeper.ssl.keystore.password=test1234\n",
    "\n",
    "[confluent@zk01 kafka]$ cat client.properties\n",
    "# Maintained by Ansible\n",
    "# Note: Secrets file for decryption when secrets protection is enabled can be found in /var/ssl/private/kafka-broker-client-security.properties\n",
    "security.protocol=SSL\n",
    "ssl.key.password=test1234\n",
    "ssl.keystore.location=/home/confluent/ssl/zk01.keystore.p12\n",
    "ssl.keystore.password=test1234\n",
    "ssl.truststore.location=/home/confluent/ssl/kafka.truststore.p12\n",
    "ssl.truststore.password=test1234\n",
    "default.api.timeout.ms=20000\n",
    "request.timeout.ms=20000\n",
    "```\n",
    "\n",
    "- Broker 기동 로그 확인:\n",
    "\n",
    "```bash\n",
    "[2023-04-18 15:58:37,653] INFO [Admin Manager on Broker 1]: **User:CN=sr-ksql01,OU=DS,O=TG,L=SEOUL,ST=SEOUL,C=KR** is updating topic _confluent_balancer_partition_samples with new configuration : cleanup.policy -> delete,retention.ms -> 3600000 (kafka.server.ZkAdminManager)\n",
    "```\n",
    "\n",
    "<aside>\n",
    "<img src=\"/icons/forward_lightgray.svg\" alt=\"/icons/forward_lightgray.svg\" width=\"40px\" /> **[DOWNLOAD] hosts-ssl.yml**\n",
    "\n",
    "[hosts-ssl.yml](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/0dd8bad1-b38e-4ef4-b367-8a97fb813ccd/hosts-ssl.yml)\n",
    "\n",
    "</aside>\n",
    "\n",
    "# Appendix. C : **Configure SASL/GSSAPI (Kerberos) authentication**\n",
    "\n",
    "### C-1. 각 서버별 Kerberos keytab 파일 준비\n",
    "\n",
    ": 아래 절차에 따라 Kerberos 서버에서 생성한 keytab파일을 Ansible Control Node로 옮겨온다.\n",
    "\n",
    "```bash\n",
    "@ kerberos 서버\n",
    "\n",
    "# ------- principal 추가 \n",
    "\n",
    "###  add_principal for zookeeper service\n",
    "sudo kadmin.local -q \"add_principal -randkey zookeeper/zk01@KAFKA.SECURE\"\n",
    "sudo kadmin.local -q \"add_principal -randkey zookeeper/br01@KAFKA.SECURE\"\n",
    "sudo kadmin.local -q \"add_principal -randkey zookeeper/sr-ksql01@KAFKA.SECURE\"\n",
    "\n",
    "###  add_principal for broker service \n",
    "sudo kadmin.local -q \"add_principal -randkey kafka/zk01@KAFKA.SECURE\"\n",
    "sudo kadmin.local -q \"add_principal -randkey kafka/br01@KAFKA.SECURE\"\n",
    "sudo kadmin.local -q \"add_principal -randkey kafka/sr-ksql01@KAFKA.SECURE\"\n",
    "\n",
    "###  add_principal for other components\n",
    "sudo kadmin.local -q \"add_principal -randkey schemaregistry/sr-ksql01@KAFKA.SECURE\"\n",
    "sudo kadmin.local -q \"add_principal -randkey connect/cn01@KAFKA.SECURE\"\n",
    "sudo kadmin.local -q \"add_principal -randkey ksql/control01@KAFKA.SECURE\"\n",
    "sudo kadmin.local -q \"add_principal -randkey controlcenter/control01@KAFKA.SECURE\"\n",
    "\n",
    "# ------- keytab 파일 생성\n",
    "\n",
    "### export principal to keytab files : zookeeper service \n",
    "sudo kadmin.local -q \"xst -kt /home/confluent/keytabs/zookeeper_zk01.service.keytab zookeeper/zk01@KAFKA.SECURE\"\n",
    "sudo kadmin.local -q \"xst -kt /home/confluent/keytabs/zookeeper_br01.service.keytab zookeeper/br01@KAFKA.SECURE\"\n",
    "sudo kadmin.local -q \"xst -kt /home/confluent/keytabs/zookeeper_sr-ksql01.service.keytab zookeeper/sr-ksql01@KAFKA.SECURE\"\n",
    "\n",
    "### export principal to keytab files : broker service \n",
    "sudo kadmin.local -q \"xst -kt /home/confluent/keytabs/kafka_zk01.service.keytab kafka/zk01@KAFKA.SECURE\"\n",
    "sudo kadmin.local -q \"xst -kt /home/confluent/keytabs/kafka_br01.service.keytab kafka/br01@KAFKA.SECURE\"\n",
    "sudo kadmin.local -q \"xst -kt /home/confluent/keytabs/kafka_sr-ksql01.service.keytab kafka/sr-ksql01@KAFKA.SECURE\"\n",
    "\n",
    "### export principal to keytab files : other components \n",
    "sudo kadmin.local -q \"xst -kt /home/confluent/keytabs/schema01.service.keytab schemaregistry/sr-ksql01@KAFKA.SECURE\"\n",
    "sudo kadmin.local -q \"xst -kt /home/confluent/keytabs/connect01.service.keytab connect/cn01@KAFKA.SECURE\"\n",
    "sudo kadmin.local -q \"xst -kt /home/confluent/keytabs/ksql01.service.keytab ksql/control01@KAFKA.SECURE\"\n",
    "sudo kadmin.local -q \"xst -kt /home/confluent/keytabs/controlcenter.service.keytab controlcenter/control01@KAFKA.SECURE\"\n",
    "\n",
    "# ------ ansible 기동 user 가 해당 keytab파일을 읽을 수 있도록 권한 조정\n",
    "sudo chown -R confluent:confluent *\n",
    "\n",
    "scp *.keytab confluent@<ansible-control-node>:~/keytabs\n",
    "```\n",
    "\n",
    "### C-2. hosts.yml 수정\n",
    "\n",
    "- sasl_protocol 명시 및 kerberos 관련 설정 추가:\n",
    "\n",
    "```bash\n",
    "---\n",
    "all:\n",
    "  vars:\n",
    "    **kerberos_configure: true\n",
    "    kerberos:\n",
    "      realm: KAFKA.SECURE ### realm configured on kerberos server \n",
    "      kdc_hostname: control02 ### kerberos server host name \n",
    "      admin_hostname: control02 ### kerberos server host name**\n",
    "```\n",
    "\n",
    "- sasl_protocol 명시 및 broker listener 설정 추가:\n",
    "\n",
    "```bash\n",
    "\t\t### sasl authentication\n",
    "    sasl_protocol: **kerberos**\n",
    "\n",
    "\t\t### kafka listeners\n",
    "\t\tkafka_broker_custom_listeners:\n",
    "      internal:\n",
    "        name: INTERNAL\n",
    "        port: 9092\n",
    "        ssl_enabled: false\n",
    "        sasl_protocol: **kerberos**\n",
    "      broker:\n",
    "        name: BROKER\n",
    "        port: 9093\n",
    "        ssl_enabled: false\n",
    "        sasl_protocol: **kerberos**\n",
    "```\n",
    "\n",
    "- 각 component 별 keytabs 파일 경로 및 principal 명시:\n",
    "\n",
    "```bash\n",
    "zookeeper:\n",
    "  # vars:\n",
    "  hosts:\n",
    "    zk01:\n",
    "\t\t\tzookeeper_kerberos_keytab_path: /home/confluent/keytabs/zookeeper_zk01.keytab \n",
    "      zookeeper_kerberos_principal: zookeeper/zk01@KAFKA.SECURE\n",
    "```\n",
    "\n",
    "### C-3. 결과\n",
    "\n",
    "- 각 컴포넌트에 생성된 kerberos client configuration\n",
    "\n",
    "```bash\n",
    "## kerberos_configure 설정 값에 따라 작성된 kerberos_client_configuration file (default: /etc/krb5.conf)\n",
    " \n",
    "[confluent@zk01 keytabs]$ cat /etc/krb5.conf\n",
    "[libdefaults]\n",
    " default_realm = KAFKA.SECURE\n",
    " dns_lookup_realm = false\n",
    " dns_lookup_kdc = false\n",
    " ticket_lifetime = 24h\n",
    " forwardable = true\n",
    " udp_preference_limit = 1\n",
    " default_tkt_enctypes = aes256-cts-hmac-sha1-96 aes128-cts-hmac-sha1-96 arc-four-hmac rc4-hmac\n",
    " default_tgs_enctypes = aes256-cts-hmac-sha1-96 aes128-cts-hmac-sha1-96 arc-four-hmac rc4-hmac\n",
    " permitted_enctypes = aes256-cts-hmac-sha1-96 aes128-cts-hmac-sha1-96 arc-four-hmac rc4-hmac\n",
    " canonicalize = True\n",
    "\n",
    "[realms]\n",
    " KAFKA.SECURE = {\n",
    "  kdc = control02:88\n",
    "  admin_server = control02:749\n",
    "  default_domain = kafka.secure\n",
    " }\n",
    "\n",
    "[domain_realm]\n",
    " .kafka.secure = KAFKA.SECURE\n",
    "  kafka.secure = KAFKA.SECURE\n",
    "```\n",
    "\n",
    "- Broker 서버에 생성된 client.properties\n",
    "\n",
    "```bash\n",
    "[confluent@zk01 kafka]$ cat client.properties\n",
    "# Maintained by Ansible\n",
    "# Note: Secrets file for decryption when secrets protection is enabled can be found in /var/ssl/private/kafka-broker-client-security.properties\n",
    "sasl.jaas.config=com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\"/etc/security/keytabs/kafka_broker.keytab\" principal=\"kafka/zk01@KAFKA.SECURE\";\n",
    "sasl.kerberos.service.name=kafka\n",
    "sasl.mechanism=GSSAPI\n",
    "security.protocol=SASL_PLAINTEXT\n",
    "default.api.timeout.ms=20000\n",
    "request.timeout.ms=20000\n",
    "```\n",
    "\n",
    "- Broker 기동 로그 확인:\n",
    "\n",
    "```bash\n",
    "[2023-03-20 10:57:09,407] INFO Successfully authenticated client: authenticationID=kafka/zk01@KAFKA.SECURE; authorizationID=kafka/zk01@KAFKA.SECURE. (org.apache.kafka.common.security.authenticator.SaslServerCallbackHandler)\n",
    "[2023-03-20 10:57:09,471] INFO Successfully authenticated client: authenticationID=kafka/sr-ksql01@KAFKA.SECURE; authorizationID=kafka/sr-ksql01@KAFKA.SECURE. (org.apache.kafka.common.security.authenticator.SaslServerCallbackHandler)\n",
    "[2023-03-20 10:57:09,498] INFO Successfully authenticated client: authenticationID=kafka/br01@KAFKA.SECURE; authorizationID=kafka/br01@KAFKA.SECURE. (org.apache.kafka.common.security.authenticator.SaslServerCallbackHandler)\n",
    "...\n",
    "\n",
    "[2023-03-20 11:07:38,577] INFO Successfully authenticated client: authenticationID=controlcenter/control01@KAFKA.SECURE; authorizationID=controlcenter/control01@KAFKA.SECURE. (org.apache.kafka.common.security.authenticator.SaslServerCallbackHandler)\n",
    "[2023-03-20 11:08:06,118] INFO Successfully authenticated client: authenticationID=ksql/control01@KAFKA.SECURE; authorizationID=ksql/control01@KAFKA.SECURE. (org.apache.kafka.common.security.authenticator.SaslServerCallbackHandler)\n",
    "```\n",
    "\n",
    "<aside>\n",
    "<img src=\"/icons/forward_lightgray.svg\" alt=\"/icons/forward_lightgray.svg\" width=\"40px\" /> **[DOWNLOAD] hosts-kerberos.yml**\n",
    "\n",
    "[hosts-kerberos.yml](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/8502f44d-fafb-4eb3-96ca-9458885459a3/hosts-kerberos.yml)\n",
    "\n",
    "</aside>\n",
    "\n",
    "# Appendix. D : Ansible 설치시 서비스 자동 시작 비활성화\n",
    "\n",
    "### D-1. hosts.yml 수정\n",
    "\n",
    "```bash\n",
    "---\n",
    "all:\n",
    "  vars:\n",
    "    **health_checks_enabled: false <<추가** \n",
    "```\n",
    "\n",
    "### D-2. roles/${COMPONENT_NAME}/tasks/main.yml 수정\n",
    "\n",
    "- main.yml 에서 Service Start 하는 task 부분의 tags를 systemd_start 로 수정\n",
    "\n",
    "```bash\n",
    "\n",
    "- name: Zookeeper Service Started\n",
    "  systemd:\n",
    "    name: \"{{zookeeper_service_name}}\"\n",
    "    enabled: true\n",
    "    state: started\n",
    "  tags:\n",
    "    - systemd_start\n",
    "```\n",
    "\n",
    "### D-3. skip-tags 옵션을 통해 PLAYBOOK 실행\n",
    "\n",
    "```bash\n",
    "ansible-playbook  -i hosts.yml  confluent.platform.all --tag zookeeper --skip-tags systemd_start\n",
    "```\n",
    "\n",
    "# Reference.\n",
    "\n",
    "- Ansible Playbooks for Confluent Platform\n",
    "    \n",
    "    [Ansible Playbooks for Confluent Platform](https://docs.confluent.io/ansible/current/overview.html)\n",
    "    \n",
    "\n",
    "- confluent platform 설치용 hosts.yml에 사용되는 role variables 별 설명\n",
    "    \n",
    "    [cp-ansible/VARIABLES.md at 7.3.3-post · confluentinc/cp-ansible](https://github.com/confluentinc/cp-ansible/blob/7.3.3-post/docs/VARIABLES.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
